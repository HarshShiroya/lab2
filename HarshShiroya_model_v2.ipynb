{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  Diagnosis  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0    842302          1      17.99      10.38     122.80     1001.0    0.11840   \n",
      "1    842517          1      20.57      17.77     132.90     1326.0    0.08474   \n",
      "2  84300903          1      19.69      21.25     130.00     1203.0    0.10960   \n",
      "3  84348301          1      11.42      20.38      77.58      386.1    0.14250   \n",
      "4  84358402          1      20.29      14.34     135.10     1297.0    0.10030   \n",
      "\n",
      "   feature_6  feature_7  feature_8  ...  feature_21  feature_22  feature_23  \\\n",
      "0    0.27760     0.3001    0.14710  ...       25.38       17.33      184.60   \n",
      "1    0.07864     0.0869    0.07017  ...       24.99       23.41      158.80   \n",
      "2    0.15990     0.1974    0.12790  ...       23.57       25.53      152.50   \n",
      "3    0.28390     0.2414    0.10520  ...       14.91       26.50       98.87   \n",
      "4    0.13280     0.1980    0.10430  ...       22.54       16.67      152.20   \n",
      "\n",
      "   feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
      "0      2019.0      0.1622      0.6656      0.7119      0.2654      0.4601   \n",
      "1      1956.0      0.1238      0.1866      0.2416      0.1860      0.2750   \n",
      "2      1709.0      0.1444      0.4245      0.4504      0.2430      0.3613   \n",
      "3       567.7      0.2098      0.8663      0.6869      0.2575      0.6638   \n",
      "4      1575.0      0.1374      0.2050      0.4000      0.1625      0.2364   \n",
      "\n",
      "   feature_30  \n",
      "0     0.11890  \n",
      "1     0.08902  \n",
      "2     0.08758  \n",
      "3     0.17300  \n",
      "4     0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_15084\\2512007381.py:11: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  data_path = \"D:\\AI\\AI in Enterprise System\\Lab2\\wdbc.data\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming the data does not have a header and is comma-separated\n",
    "# You might need to adjust the path to where your file is located\n",
    "data_path = \"D:\\\\AI\\\\AI in Enterprise System\\\\Lab2\\\\wdbc.data\"\n",
    "\n",
    "# Define column names manually based on the dataset description\n",
    "column_names = ['ID', 'Diagnosis'] + [f'feature_{i}' for i in range(1, 31)]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path, header=None, names=column_names)\n",
    "\n",
    "# Map diagnosis to a binary variable\n",
    "df['Diagnosis'] = df['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Diagnosis', data=df)\n",
    "plt.title('Distribution of Target Classes')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(df.corr(), annot=False, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X = df.drop('Diagnosis', axis=1)\n",
    "y = df['Diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
